# R-CNN

- R-CNN이란? Image classification을 수행하는 CNN과 localization을 위한 regional proposal을 연결한 모델

- R-CNN의 전반적인 흐름

 ![r-cnn](https://user-images.githubusercontent.com/66320010/104412647-0f0c4700-55b0-11eb-83d7-a575a831ffdc.png)
 
위의 사진은 논문에 기재된 R-CNN의 전반적인 흐름이며 
 
![r-cnn2](https://user-images.githubusercontent.com/66320010/104417621-0cfab600-55b9-11eb-8512-5d6cb3190748.png)

이 사진은 R-CNN의 흐름을 더 보기 좋게 그린 도표이다.

R-CNN의 수행 과정은 다음과 같다.

1. 입력 이미지에 Selective Search 알고리즘을 적용하여 물체가 있을만한 박스 2000개를 추출한다.

2. 추출한 박스를 227 x 227 크기로 리사이즈(wrap)한다. 이 때 박스의 비율은 고려하지 않는다. 

**왜 동일 input size로 만들어주는가? Convolution Layer에서는 input size가 고정적이지 않으나 FC Layer(Fully Connected Layer)에서 input size가 고정이므로 Convolution Layer에 대한 output size도 동일해야한다. 따라서 Convolution Layer의 입력에서부터 동일한 input size를 넣어주어 output size를 동일하게 하는 것이다.**

3. 미리 학습시킨 CNN을 통과시켜 4096차원의 특징 벡터를 추출한다.

4. 추출된 벡터를 가지고 각각의 클래스마다 학습시켜놓은 SVM Classifier를 통과한다.

5. Bounding Box Regression을 적용하여 박스의 위치를 조정한다.

# 1. Region Proposal

- Region Proposal이란? 주어진 이미지에서 물체가 있을법한 위치를 찾는 것

R-CNN은 Selective Search라는 룰 베이스 알고리즘을 적용하여 물체가 있을법한 2000개의 박스를 찾는다. 

![selective search](https://user-images.githubusercontent.com/66320010/104414655-fbfb7600-55b3-11eb-8d17-3a2a52103bcd.png)

Selective Search는 주변 픽셀 간의 유사도를 기준으로 Segmentation을 만들고, 이를 기준으로 물체가 있을법한 박스를 추론한다. 

(하지만 R-CNN이후 Region proposal과정이 뉴럴 네트워크가 수행하도록 발전하여 잘 사용되어지지 않는 알고리즘이 되었다)

# 2. Feature Extraction(using CNN)

![image](https://user-images.githubusercontent.com/66320010/104415179-df137280-55b4-11eb-8ec4-14e14c660765.png)

앞에서 Selective Search를 통해서 찾아낸 2000개의 박스 영역은 227 x 227 크기로 리사이즈(wrap)되는데 이를 Image Classification으로 미리 학습되어 있는 CNN 모델에 넣어준다.

여기서 CNN은 AlexNet의 구조를 거의 그대로 가져다 썼으며, Object Detetion 용으로 마지막 부분만 조금 수정되었다.

저자들은 이미지넷 데이터(ILSVRC2012 classification)로 미리 학습된 CNN 모델을 가져온 다음, fine tune하는 방식을 취했다.

fine tune 시에는 실제 Object Detection을 적용할 데이터 셋에서 ground truth에 해당하는 이미지들을 가져와 학습시켰고, Classification의 마지막 레이어를 Object Detection의 클래스 수 N과 아무 물체도 없는 배경까지 포함한 N+1로 맞춰주었다.

![ft](https://user-images.githubusercontent.com/66320010/104415990-55fd3b00-55b6-11eb-8cfc-59a968e723cc.png)

위의 사진은 fine tune을 적용했을 때와 적용하지 않았을 때의 성능을 비교한 것이다.

FT는 fine tune의 약자이며, 각 CNN 레이어 층에서 추출된 벡터로 SVM Classfier를 학습시켜 얻은 mAP를 비교한 것이다(mAP는 Object Detection 분야에서 많이 사용되는 정확도 측정 지표를 의미)

위의 사진을 보면 전반적으로 fine tuning을 적용한 것들이 성능이 더 좋음을 확인할 수 있다.

**정리하자면 미리 학습된 CNN을 가져와서 Object Detection용 데이터 셋으로 fine tuning한 뒤 selective search 결과로 뽑힌 이미지들로부터 특징 벡터를 추출한다는 것이다.**

# 3. Classification

![classification](https://user-images.githubusercontent.com/66320010/104416607-7083e400-55b7-11eb-9b6e-c1044fee02a5.png)

CNN을 통해 추출한 벡터를 가지고 각각의 클래스 별로 SVM Classifier를 학습시킨다. 

주어진 벡터를 놓고 이것이 해당 물체가 맞는지 아닌지를 구분하는 Classifier모델을 학습시키는 것이다.

**이미 학습되어 있는 CNN classifier를 두고 왜 SVM을 별도로 학습시키는가? 저자들은 "그냥 CNN Classifier를 쓰는 것이 SVM을 썼을 때보다 mAP 성능이 4% 정도 낮아졌다. 이는 아마도 fine tuning 과정에서 물체의 위치 정보가 유실되고 무작위로 추출된 샘플을 학습하여 발생한 것으로 보인다." 고 답변했다.**


# 4. Non-Maximum Suppression

![nms](https://user-images.githubusercontent.com/66320010/104419035-3f0d1780-55bb-11eb-82d0-8ec97d6d8d14.png)

SVM을 통과하여 이제 2000개의 박스들은 어떤 물체일 확률 값(Score)을 가지게 되는데 2000개의 박스가 모두 필요한 것일까?

동일한 물체에 여러 개의 박스가 쳐져있는 것이라면, score가 가장 높은 박스만 남기고 나머지는 제거해야한다.

이 과정을 **Non-Maximum Suppression**라고 한다.

만약 서로 다른 두 개의 박스가 동일한 물체에 쳐져 있다고 했을 때 어떻게 판별할 수 있을까? 

여기서 **IoU(Intersection over Union)** 개념이 적용된다.

![image](https://user-images.githubusercontent.com/66320010/104419366-b8a50580-55bb-11eb-968b-dbd77675ee7f.png)

![image](https://user-images.githubusercontent.com/66320010/104419295-9ad7a080-55bb-11eb-83fb-479960f01e3a.png)


IoU란 쉽게 말하면 두 박스의 교집합을 합집합으로 나눠준 값이다. 두 개의 박스가 일치할 수록 1에 가까운 값이 나오게 된다.

논문에서는 IoU가 0.5 보다 크면 동일한 물체를 대상으로 한 박스로 판단하고 Non-Maximum Suppression을 적용한다.

# 5. Bounding Box Regression

지금까지 Selective Search로 물체가 있을 법한 위치를 Bounding Box로 표시해주었고 해당 물체의 종류를 판별할 수 있는 classification 모델을 학습시켰다.

하지만 Selective Search를 통해서 찾은 박스 위치는 완전히 정확하지는 않기 때문에 물체를 정확히 감싸도록 조정해주는 선형회귀 모델(Bounding Box Regression)을 사용한다.

먼저 하나의 박스는 다음과 같이 표기할 수 있다. 

![image](https://user-images.githubusercontent.com/66320010/104420025-a081b600-55bc-11eb-897b-97858b507686.png)

여기서 x,y는 이미지의 중심점, w와 h는 각각 너비와 높이를 의미한다.

Ground Truth에 해당하는 박스는 다음과 같이 표기할 수 있다.

![image](https://user-images.githubusercontent.com/66320010/104420101-b7c0a380-55bc-11eb-8efe-340d88ecd6bc.png)

목표는 P에 해당하는 박스를 최대한 G에 가깝게 이동시키는 함수를 학습시키는 것이다. 박스가 input으로 들어왔을 때 x,y,w,h를 각각 이동시켜주는 함수들은 다음과 같이 표현할 수 있다.

![image](https://user-images.githubusercontent.com/66320010/104420520-551bd780-55bd-11eb-9f5e-e9223564efba.png)

이 때 x,y는 점이기 때문에 이미지의 크기에 상관없이 위치만 이동시켜주면 된다. 하지만 w,h(너비,높이)는 이미지의 크기에 비례하여 조정을 시켜주어야한다.

이러한 특성을 반영하여 P를 이동시키는 함수의 식을 짜보면 다음과 같다.

![image](https://user-images.githubusercontent.com/66320010/104420629-80062b80-55bd-11eb-91ea-4c9750e427f1.png)

우리가 학습을 통해 얻고자 하는 것은 d함수이다. 저자들은 이 d함수를 구하기 위해서 앞에서 CNN을 통과할 때 pool5 레이어에서 얻어낸 특징벡터를 이용한다. 그리고 함수에 학습 가능한 weight 벡터를 주어 계산한다.

이를 식으로 나타내면 다음과 같다.

![image](https://user-images.githubusercontent.com/66320010/104420795-c3f93080-55bd-11eb-81a1-2d03e87d5b51.png)

이제 weight를 학습시킬 loss function을 세워보면 다음과 같다. 

![image](https://user-images.githubusercontent.com/66320010/104421155-4f72c180-55be-11eb-9a32-f0b1055ca13d.png)

일반적인 MSE(평균제곱오차)함수에 L2 normalization을 추가한 형태이다. 논문에서 람다 값은 저자들이 1000으로 설정하였다.

그리고 여기서 t는 P를 G로 이동시키기 위해서 필요한 이동량을 의미하며 식으로 나타내면 아래와 같다.

![image](https://user-images.githubusercontent.com/66320010/104422150-b349ba00-55bf-11eb-83bc-c5dc856085e5.png)

**정리를 해보면 CNN을 통과하여 추출된 벡터와 x,y,w,h를 조정하는 함수의 weight를 곱해서 bounding box를 조정해주는 선형 회귀를 학습시키는 것이다.**



# 정리

- R-CNN에서 학습이 일어나는 부분

1. 이미지 넷으로 이미 학습된 CNN모델을 가져와 fine tuning하는 부분

2. SVM Classifier를 학습시키는 부분

3. Bounding Box Regression

- 속도 및 정확도

![image](https://user-images.githubusercontent.com/66320010/104421955-7251a580-55bf-11eb-9662-094036a114b6.png)

위 그림에서 R-CNN BB라고 기재되어있는 맨 아래 행은 Bounding Box Regression을 적용한 경우이다. Bounding Box Regression을 적용시켰을 때 성능이 더 향상 되는 것을 확인할 수 있다. Pascal VOC  2010을 기준으로 53.7%를 기록하였고 이는 당시 기존의 기록들을 모두 갈아치우며 획기적으로 Object Detection 분야에 발전을 이끌었던 score이다.

- R-CNN의 단점 및 결론

**1. 오래걸린다** 

R-CNN은 Selective Search로 뽑아낸 2000개의 영역 이미지들에 대해서 모두 CNN 모델에 들어가게 되어 오래걸릴 수 밖에 없는 구조가 된다. 또한 Selective Search가 CPU를 사용하는 알고리즘이기 때문에 시간 소요가 많이 된다.

R-CNN의 수행시간은 Training Time: 84시간, Testing Time은 GPU K40 사용 기준으로 frame당 13초이며 CPU를 사용하였을 때는 frame당 53초가 걸린다.

**2. 복잡하다**

R-CNN은 CNN, SVM, 그리고 Bounding Box Regression까지 총 세 가지의 모델을 따로 학습해야한다.

**3. Back Propagation이 안된다.**

R-CNN은 Multi-Stage Training을 수행하여 SVM, Bounding Box Regression에서 학습한 결과가 CNN을 업데이트 시키지 못한다.

**이러한 문제점을 해결하기 위해 Fast R-CNN이 제안되었다.**
 






