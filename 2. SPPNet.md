# SPPNet(Spatial Pyramid Pooling Network)

- SPPNet의 핵심 아이디어

기존의 CNN 아키텍처들은 입력 이미지가 고정되어야 했다. 그렇기 때문에 신경망을 통과하기 위해서 이미지를 고정된 크기로 crop하거나 warp해야 했다.

하지만 이렇게 되면 물체의 일부분이 잘리거나, 본래의 생김새와 달라지는 문제점이 있다 => **여기서 아이디어를 얻어 SPPNet이 시작되었다.**

![image](https://user-images.githubusercontent.com/66320010/104425952-a1b6e100-55c4-11eb-8c90-b586ad163a79.png)

위 그림은 crop이나 warp를 하면 왜곡이 발생하는 것을 보여준다. 

앞서 R-CNN에서 언급했던 것처럼 Convolution 필터들은 사실 입력 이미지가 고정될 필요가 없다. sliding window 방식으로 작동하기 때문에, 입력 이미지의 크기나 비율에 관계 없이 작동한다.

하지만 입력 이미지 크기의 고정이 필요한 이유는 바로 컨볼루션 레이어들 다음에 이어지는 fully connected layer가 고정된 크기의 입력을 받기 때문이다.

따라서 SPPNet이 제안되었다. 

**"입력 이미지의 크기에 관계 없이 Convolution layer들을 통과시키고, FC layer 통과 전에 피쳐 맵들을 동일한 크기로 조절해주는 pooling을 적용하자!"**

입력 이미지의 크기를 조절하지 않은 채로 convolution을 진행하면 원본 이미지의 특징을 그대로 가지고 있는 특징 맵을 얻을 수 있다. 또한 사물의 크기 변화에 더 견고한 모델을 얻을 수 있다는 것이 저자들의 주장이다.

- 전체 알고리즘

![image](https://user-images.githubusercontent.com/66320010/104442952-1f84e780-55d9-11eb-9df7-db3e7cb111d5.png)

1. 전체 이미지를 미리 학습된 CNN에 통과시켜 feature map을 추출한다.

2. Selective Search를 통해서 찾는 각각의 RoI들은 크기와 비율이 다르다. 이에 SPP를 적용하여 고정된 크기의 feature vector를 추출한다.

3. 그 다음 fully connected layer들을 통과 시킨다.

4. 앞에서 추출한 벡터로 각 이미지 클래스 별로 binary SVM classifier를 학습시킨다.

5. 마찬가지로 앞에서 추출한 벡터로 bounding box regressor를 학습시킨다.

**핵심은 SPP를 통해 크기가 다른 CNN feature map input으로부터 고정된 크기의 feature vector를 뽑아내는 것이다.** 그 이후의 접근 방식은 R-CNN과 거의 동일하다.

# 1. SPP(Spatial Pyramid Pooling)

![image](https://user-images.githubusercontent.com/66320010/104430392-f3ae3580-55c9-11eb-8e79-6235e87d6078.png)

먼저 convolution layer들을 거쳐 추출된 feature map을 input으로 받는다. 그리고 이를 미리 정해져 있는 영역으로 나누어 준다. 예시에서는 미리 4x4, 2x2, 1x1 세 가지 영역으로 나누었고, 각각을 하나의 피라미드라고 부른다.

즉, 해당 예시에서는 3개의 피라미드를 제공한 것이다. 피라미드 한 칸은 bin이라고 부르는데 예를 들어 input으로 64x64x256크기의 feature map이 들어온다고 할 때 4x4 피라미드의 bin크기는 16x16이 되는 것이다.

그 후 각 bin에서 가장 큰 값만 추출하는 max pooling을 수행하고 그 결과를 쭉 이어서 붙여준다. 이 때 feature map의 채널 크기를 k, bin의 갯수를 M이라고 했을 때 SPP의 최종 output은 kM차원의 벡터이다.

위의 예시에서는 k가 256, M이 16+4+1해서 21이다. 

**정리해보면 입력 이미지의 크기와는 상관없이 미리 설정한 bin 개수와 CNN 채널 값으로 SPP의 출력이 결정되므로 항상 동일한 크기의 결과를 return한다고 볼 수 있다.**

실제 실험에서 저자들은 1x1, 2x2, 3x3, 6x6 총 4개의 피라미드로 SPP를 적용한다.

# 2. Object Detection에의 적용

![image](https://user-images.githubusercontent.com/66320010/104442675-bc935080-55d8-11eb-9165-96cf54010c6a.png)

![image](https://user-images.githubusercontent.com/66320010/104440506-cb2c3880-55d5-11eb-9f1c-08db6e679dce.png)

object detection에 SPP를 적용할 수 있는데 R-CNN은 Selective Search로 찾은 2000개의 물체 영역을 모두 고정크기로 조절한 다음, 미리 학습된 CNN모델을 통과시켜 추출한다. 그래서 속도가 느릴 수 밖에 없다.

하지만 SPPNet은 입력 이미지를 그대로 CNN에 통과시켜 feature map을 추출한 다음 그 feature map에서 2000개의 물체 영역을 찾아 SPP를 적용하여 고정된 크기의 feature map을 얻어낸다. 그리고 이를 FC와 SVM Classifier에 통과시킨다.
**(주의! 원래 이미지에서 selective search를 해서 그 영역들을 가지고 있고, 이미지 전체를 CNN해서 나온 Feature map하고 그 영역들을 합쳐주는 것이다.)**

# 한계점

SPPNet은 기존 R-CNN이 모든 RoI에 대해서 CNN inference를 한다는 문제점을 획기적으로 개선하였으나 한계점이 존재한다.

**1. end-to-end 방식이 아니라 학습에 여러 단계가 필요하다**

  fine tuning, SVM training, Bounding Box Regression -> 학습이 3번 필요

**2. fine tuning시에 SPP를 거치기 이전의 Convolution layer들을 학습시키지 못한다. 단지 FC Layer만 학습시킨다.**

**3. 최종 classificcation은 binary SVM, Region proposal은 Selective Search를 사용한다.**






