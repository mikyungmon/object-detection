# Fast R-CNN

- Fast R-CNN 핵심 아이디어

Fast R-CNN은 SPPNet이 가지는 한계점들을 극복하고자 하는 시도에서 출발한다.

SPPNet은 기존 R-CNN이 Selective Search로 찾아낸 모든 RoI에 대해서 CNN inference를 하는 문제를 CNN inference를 전체 이미지에 대하여 1회만 수행하고, 이 feature map을 공유하는 방식으로 해결했다.

그러나 여전히 모델을 학습시키기 위해서는 여러 단계를 거쳐야했고, FC Layer밖에 학습시키지 못하는 한계점이 있었다. 

따라서 **CNN 특징 추출부터 classification, bounding box regression 까지 모두 하나의 모델에서 학습시키자!"** 가 Fast R-CNN의 핵심 주장이다.

- 전체 알고리즘

![image](https://user-images.githubusercontent.com/66320010/104447708-83121380-55df-11eb-8ef1-247b8bf9c921.png)

![image](https://user-images.githubusercontent.com/66320010/104450777-f584f280-55e3-11eb-85f1-93f18c8987ef.png)

0. input Image에 Selective Search를 진행하여 RoI영역을 미리 뽑아놓는다.

1. 먼저 전체 이미지를 미리 학습된 CNN을 통과시켜 feature map을 추출한다.

2. Selective Search를 통해서 찾은 각각의 RoI에 대하여 RoI Pooling을 진행한다. 그 결과로 고정된 크기의 feature vector를 얻는다.

3. feature vector는 fully connected layer들을 통과한 뒤, 두 개의 브랜치로 나뉘게 된다

하나의 브랜치는 softmax를 통과하여 해당 RoI가 어떤 물체인지 classification한다. 이제 SVM은 사용되지 않는다.

다른 하나의 브랜치는 bounding box regression을 통해 selective search로 찾은 박스의 위치를 조정한다.

CNN을 통과시킨 뒤, 그 feature map을 공유하는 것은 이미 SPPNet에서 제안된 방법이다. 그 이후의 스텝들은 SPPNet이나 R-CNN과 그다지 다르지 않다. **본 논문의 가장 큰 특징은 이들을 스텝별로 쪼개어 학습을 진행하지 않고, end-to-end로 엮었다는데 있으며 그 결과로 학습 속도, 인퍼런스 속도, 정확도 모두를 향상시켰다는데 의의가 있다.**

# 1. CNN(Convolutional Neural Network)

![image](https://user-images.githubusercontent.com/66320010/104448580-b4d7aa00-55e0-11eb-8e26-c92ed5a89fe2.png)

이전 R-CNN에서는 Selective Search로 뽑아낸 Region Proposal 후보들(2000개)을 모두 CNN 모델에 집어 넣어 굉장히 시간이 많이 걸렸다. 

하지만 Fast R-CNN은 R-CNN과 다르게 뽑아낸 영역을 Crop하지 않고 그대로 가지고 있고, 전체 이미지를 CNN Model에 집어 넣은 후 CNN으로부터 나온 Feature Map에 RoI Projection을 하는 방식을 택했다.(SPPnet에서 보완한 R-CNN의 단점과 동일하다)

**즉, input image 1장으로부터 CNN Model에 들어가는 이미지는 2000장 -> 1장이 된 것이다.**

# 2. RoI (Region of Interest) Pooling

![image](https://user-images.githubusercontent.com/66320010/104449026-5101b100-55e1-11eb-87cc-0a3db1df3302.png)

위 그림처럼 Projection시킨 RoI를 FCs(Fully Connected Layer)에 넣기 위해서는 같은 Resolution의 Feature map이 필요하다. 

하지만 Selective Search를 통해 구해졌던 RoI 영역은 각각 다른 크기를 가지고 있다. 따라서 이 Resolution의 크기를 맞춰주기 위해 **RoI Pooling**을 수행한다.

RoI Pooling은 간단히 말해서 크기가 다른 Feature Map의 Region마다 Stride를 다르게 Max Pooling을 진행하여 결과값을 맞추는 방법이다.

![image](https://user-images.githubusercontent.com/66320010/104450059-e18cc100-55e2-11eb-95ea-43f772873e60.png)

위와 같이 8x8 input feature map에서 Selective Search로 뽑아냈던 7x5 짜리 Region Proposal 부분이 있고, 이를 2x2로 만들어주기 위해 Stride (7/2 = 3, 5/2 = 2) 로 Pooling Sections를 정하고 Max pooling 하여 2x2 output을 얻어낸다.

즉, 추출된 Feature Map을 미리 정해놓은 H x W 크기에 맞게끔 그리드를 설정하고 각각의 칸 별로 가장 큰 값을 추출하는 max pooling을 실시하면 결과값은 항상 H x W 크기의 Feature Map이 되고, 이를 쫙 펼쳐서 feature vector를 추출하게 되는 것이다 => 이러한 RoI Pooling은 앞서 살펴보았던 Spatial Pyramid Pooling에서 피라미드 레벨이 1인 경우와 동일하다.

# 3. Classification & Bounding Box Regression

![image](https://user-images.githubusercontent.com/66320010/104450578-aa6adf80-55e3-11eb-99e4-d76a8e939661.png)

마지막으로 Fixed Length Feature Vector를 FCs(Fully Connected Layer)에 집어 넣은 후 두 브랜치로 뻗어 나가 Classification과 Bounding box Regression을 진행한다.

- Loss Function(Multi Task Loss)

![image](https://user-images.githubusercontent.com/66320010/104451219-9673ad80-55e4-11eb-95cb-ac1cd9a67522.png)

입력 이미지로부터 Feature map을 추출했고, 해당 Feature map에서 RoI들을 찾아서 RoI Pooling을 적용하여 fixed length feature vector를 구했으며 이제 이 벡터로 classification과 bounding box regression을 적용하여 각각의 loss를 얻어내고, 이를 back propagation하여 전체 모델을 학습시키면 된다.

이 때, classificaiton loss와 bounding box regression을 적절하게 엮어주는 것이 필요하며, 이를 **multi task loss**라고 한다.

Fast-RCNN은 Loss Function으로 Multi-task Loss를 사용하였다. R-CNN에서는 Classification과 Bounding box Regression을 따로 학습했지만 Fast R-CNN에서는 위의 사진과 같이 두 Loss를 더하여 동시에 학습한 것이다.

Classfication Loss에는 Log Loss를 사용, Bbox Regression Loss에는 Smooth L1 Loss를 사용하였다.

먼저 입력으로 p는 softmax를 통해서 얻어낸 K+1 (K개의 object + 1개의 배경, 아무 물체도 아님을 나타내는 클래스)개의 확률 값이며 그다음 u는 해당 RoI의 ground truth 라벨 값이다.

그 다음으로 bounding box regression을 적용하면 이는 K + 1개 클래스에 대해서 각각 x, y, w, h 값을 조정하는 𝑡^𝑘를 리턴한다. 즉, 이 RoI가 사람일 경우 박스를 이렇게 조절하라, 고양이일 경우 이렇게 조절하라는 값을 리턴하는 것이다.

loss function에서는 이 값들 가운데 ground truth 라벨에 해당하는 값만 가져오며, 이는 𝑡^u에 해당하며 𝑣는 ground truth bounding box 조절 값에 해당한다.

![image](https://user-images.githubusercontent.com/66320010/104452620-98d70700-55e6-11eb-9013-ad7680e469c9.png)

다시 전체 로스로 돌아가보면 앞부분은 p와 u를 가지고 classification loss를 구한다. 여기서는 위와 같이 log loss를 사용한다.

전체 로스의 뒷 부분은 Bounding Box Regression을 통해서 얻는 loss로 수식은 아래와 같다.

![image](https://user-images.githubusercontent.com/66320010/104452703-b6a46c00-55e6-11eb-93b9-f4fd4c1077d8.png)

입력으로는 정답 라벨에 해당하는 Bounding Box Regression 예측 값과 ground truth 조절 값을 받는다. 그리고 x, y, w, h 각각에 대해서 예측 값과 라벨 값의 차이를 계산한 다음, smoothL1이라는 함수를 통과시킨 합을 계산한다. smoothL1은 아래와 같다.

![image](https://user-images.githubusercontent.com/66320010/104452773-cc199600-55e6-11eb-97fc-0fc4ecd8a03b.png)

예측 값과 라벨 값의 차가 1보다 작으면 0.5x^2로 L2 distance를 계산해준다. 반면에 1보다 클 경우 L1 distance를 계산해주는 것을 볼 수 있다. 

이는 Object Detection 테스크에 맞추어 loss function을 커스텀 하는 것으로 볼 수 있다. 저자들은 실험 과정에서 라벨 값과 지나치게 차이가 많이 나는 outlier 예측 값들이 발생했고, 이들을 그대로 L2 distance로 계산하여 적용할 경우 gradient가 explode 해버리는 현상을 관찰하여 이를 방지하기 위해서 다음과 같은 함수를 추가한 것이다.

# 3. Contribution

논문에서 언급한 Fast R-CNN의 contribution은 다음과 같다.

![image](https://user-images.githubusercontent.com/66320010/104453870-67f7d180-55e8-11eb-9afd-3dd6884709d3.png)

**1. 뛰어난 성능**

![image](https://user-images.githubusercontent.com/66320010/104453651-151e1a00-55e8-11eb-9819-65b356b85ef6.png)

Fast R-CNN은 R-CNN과 SPPnet을 뛰어넘는 성능을 보였다. PASCAL VOC 2012 데이터를 기준으로 66%의 mAP를 얻어냈다. (R-CNN은 62%)

또한 Fast R-CNN은 R-CNN에 비해서 엄청나게 빨라진 속도를 보인다. 하지만 Test Time 그래프를 보면 Region Proposal에 걸리는 시간이 전체 Test time 2.3초에서 2초 정도를 차지하는 것을 확인할 수 있다.
 
이유는, Region Proposal에 사용되는 Selective Search가 GPU가 아닌 CPU를 사용하는 알고리즘이기 때문인데 **이 문제를 Faster R-CNN에서는 해결하였다.*

**2. Single Stage Training**

End-to-end로 Single Stage Training을 진행한다. 하지만 Fast R-CNN은 Training은 Single Stage이지만 Single Stage Detector는 아니라고 본다. 왜냐하면 Region Proposal로 Selective Search를 수행하기 때문이다. (Selective Search는 CPU로 수행하며 학습되지 않는다) 전체적으로는 2-Stage Detector로 보는게 맞을 것 같다.

그리고 위 Loss Function에서 설명한 것처럼 Multi-task Loss를 사용.

**3. Backpropagation 가능**

모든 Computation을 Share하여 End-to-End Training을 진행한다. 따라서 Backpropagation(역전파)이 가능하다.

**4. 저장공간이 필요 없다.**

R-CNN의 경우에 CNN에서 나온 Feature Map을 Disk에 집어 넣고 SVM을 진행할 때 불러오는 방식으로 진행 했으며 이미지 1개당 2000개의 Feature Map이 나와 큰 용량이 필요했다.

하지만 Fast-RCNN은 이와 같은 과정이 필요 없어졌다.

# 5. 단점 및 정리

Fast R-CNN 논문은 R-CNN이나 SPP-net에 비하면 뛰어난 성능을 보이고 위와 같은 Contribution들을 가지고 있으며, 앞의 논문들이 가지고 있었던 많은 문제들을 해결하였다. (object detection 테스크를 푸는 end-to-end 모델을 제시하면서 학습 단계를 간소화시키고 정확도와 성능 모두를 향상시켰다는 의의가 있다.) 

하지만 이미지 한 장당 2.3초의 Test time이 걸리는 알고리즘은 Real-time Object Detector로는 부족하다.

게다가 Region Proposal에 걸리는 총 2.3초 중 2초의 시간 때문에 Bottleneck이 생기는 구조이다.

이 문제들을 해결 하기 위해 비슷하지만 다른 구조의 **Faster R-CNN**이 제안되었다.

 
