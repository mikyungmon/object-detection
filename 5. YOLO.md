# YOLO(You Only Look Once) #

- YOLO란?

  - YOLO는 You Only Look Once, 즉 이미지를 한 번 보는 것만으로 물체의 종류와 위치를 추측하는 딥러닝 기반의 물체인식 알고리즘을 뜻한다.

  - YOLO는 2015년에 나온 논문으로 Faster R-CNN에 비하여 부려 6배 가량 빠른 속도를 보인다. 정확도는 비록 조금 낮다 하더라고 정말 비약적인 발전이라고 할 수 있다.
  
  - **주요 기여 : 1 Step Object Detection 기법을 제시하였으며, fps가 무려 45로 속도 측면에서 획기적인 발전을 이루었다.**
  
 ![image](https://user-images.githubusercontent.com/66320010/107498757-8648f100-6bd7-11eb-893f-3743f809d67e.png)

  기존 R-CNN 계열의 검출 네트워크들은 이미지 안에서 bounding box를 생성하기 위해 region proposal이라는 방법을 사용한다.
  
  그렇게 제안된 bounding box에 classifier를 적용하여 분류(classification)한 뒤 bounding box를 조정하고, 중복된 검출을 제거하고, 객체에 따라 box의 점수를 재산정하기 위해 후처리(post-processing)를 한다.
  
  **=> 이런 복잡함 때문에 R-CNN은 속도가 느려지며 각 절차를 독립적으로 훈련시켜야 하므로 최적화(optimization)하기도 힘들다.**
  
  따라서 저자들은 객체 검출을 하나의 회귀 문제로 보고 절차를 개선하였다. 이미지의 픽셀로 부터 bounding box의 위치(coordinates), 클래스 확률(class probabilities)을 구하기까지의 일련을 절차를 하나의 회귀 문제로 재정의하였다.
  
  이러한 시스템을 통해 YOLO는 이미지 내에 어떤 물체가 있고 그 물체가 어디에 있는지를 하나의 파이프라인으로 구한다.
  
# Unified Detection #
  
YOLO가 기존의 object detection과 가장 크게 구분되는 부분은 기존에 1) region proposal 2) classification 이렇게 두 단계로 나누어 진행하던 방식에서 region proposal 단계를 제거하고 한번에 object detection을 수행하는 구조는 갖는다는 점이다.
  
![image](https://user-images.githubusercontent.com/66320010/107503026-cc548380-6bdc-11eb-9a18-e8c6af782c04.png)

위의 그림은 YOLO의 1 step 구조를 간단히 보여준다.

1) 먼저 입력 이미지를 S * S 그리드 영역으로 나눈다(실제 입력 이미지를 나누는 것은 아니다)

2) 각 그리드 영역에서 먼저 물체가 있을만한 영역에 해당하는 B개의 Bounding Box를 예측한다(이는 x,y,w,h로 나타내어 지는데 x,y는 bounding box의 중심점 좌표이며 w와h는 각각 너비와 높이이다)
  
3) 다음으로 해당 박스의 신뢰도를 나타내는 confidence를 계산한다(이는 해당 그리드에 물체가 있을 확률 Pr(Object)과 예측한 박스와 Ground Truth 박스와의 겹치는 영역을 비율을 나타내는 IoU를 곱해서 계산한 값을 의미한다)

![image](https://user-images.githubusercontent.com/66320010/107503730-a8457200-6bdd-11eb-9806-b06492e0c5cd.png)

4) 각각의 그리드마다 C개의 class에 대해 해당 클래스일 확률을 계산하며 수식은 아래 사진과 같다.

![image](https://user-images.githubusercontent.com/66320010/107503896-db880100-6bdd-11eb-8745-c656f8b0ffdc.png)

**이 때, 특이한 점은 기존의 Object Detection에서는 항상 클래스 수 + 1 (배경)을 집어넣어 classification을 하는데, yolo는 그렇지 않다.**
  
 # Network Design # 
 
 ![image](https://user-images.githubusercontent.com/66320010/107504335-77b20800-6bde-11eb-9c4c-345586f913bd.png)
 
 위의 그림은 YOLO의 전체 네트워크 구조를 보여준다. 
 
 YOLO는 24개의 Convolutional Layer(Conv Layer)와 2개의 Fully-Connected Layer(FC Layer)로 연결된 구조를 사용하고 있다.
  
  - Pre-trained Network
  
    주황색 테두리로 표현한 부분은 GoogLeNet을 이용하여 ImageNet 1000-class dataset을 사전에 학습한 결과를 Fine-Tuning한 네트워크를 말한다 (이 네트워크는 20개의 Conv Layer로 구성되어 있다)
  
    본 논문에서는 이 모델에서 88%의 정확도를 사전에 학습했다고 한다. 본래 ImageNet의 데이터 셋은 224x224의 크기를 가진 이미지 데이터이지만, 물체 인지를 학습할 때는 선명한 이미지 보다는 경계선이 흐릿한 이미지가 더 학습이 잘된다고 해서 Scale Factor를 2로 설정하여 이미지를 키워 448 x 448 x 3의 이미지를 입력 데이터로 받는다.
    
  - Reduction Layer
  
    보통 네트워크는 깊을 수록 더 많은 특징을 학습하기 때문에 정확도가 높아지는 경향이 있다. 하지만 Conv Layer를 통과할 때 사용하는 Filter 연산이 수행시간을 많이 잡아 먹기 때문에 무작정 네트워크를 깊게 쌓기에는 부담이 된다. 
  
    이 문제를 해결하기 위해 ResNet, GoogLeNet 등의 기법이 제안되었는데 오렌지 색 테두리로 된 영역에서는 GoogLeNet의 기법을 응용 하여 연산량은 감소하면서 층은 깊게 쌓는 방식을 이용하였다.
  
  - Training Network
  
    파란색 영역인 Training Network는 Pre-trained Network에서 학습한 feature를 이용하여 Class probability와 Bounding box를 학습하고 예측하는 네트워크이다.
    
    YOLO의 예측 모델은 S x S x (B * 5 + C) 개의 파라미터를 결과로 출력한다.
   
![image](https://user-images.githubusercontent.com/66320010/107505100-8f3dc080-6bdf-11eb-966a-90b4aeab733d.png)
 
해당 그림은 YOLO의 좀 더 직관적인 그림이다.
  
