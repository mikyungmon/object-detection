# YOLO v2 #

YOLO v2는 기존 YOLO 알고리즘의 두 번째 버전으로, 정확도를 높인 모델이며 YOLO v2 모델을 기반으로 무려 9000종류의 물체를 구분할 수 있는 YOLO 9000 모델을 공개하였다.

-> 이전까지 Object Detection 분야에서 가장 많이 사용되었던 데이터 셋인 coco가 약 80종류의 클래스를 가진 것과 비교하면 파격적

저자들은 해당 논문을 크게 **Better, Faster, Stronger**으로 나누었다.

# 1. Better #

Better 챕터에서 저자는 기존 YOLO 모델의 한계점으로 지적되었던 **정확도**를 어떻게 개선하였는지를 설명한다(어떤 방법들을 이용하여 recall과 localization성능을 높였는지)

**<성능 향상 요인>**

1) Batch normalization - 모든 컨볼루션 레이어에 배치 정규화를 추가

2) High Resolution Classifier - 높은 해상도 이미지로 backbone CNN 네트워크 fine tune

3) Anchor box - 경계 박스를 처음부터 직접 예측 -> 앵커 박스를 초기값으로 사용하여 예측

    3-1) Convolutional With Anchor Boxes - 기존 yolo에서 Fully Connected Layer를 떼어내고 Fully Convolutional Network 형태로 prediction을 계산

    3-2) Dimension Cluster - 실제 경계 박스들을 클러스터링하여 최적의 앵커박스를 찾음

    3-3) Direct Location Prediction - 경계 박스가 그리드 셀에서 벗어나지 않게 제약을 둠

4) Fine-Grained Features - 최종 feature map의 크기를 7x7에서 13x13으로 키움

5) Multi-Scale Training - 학습데이터의 크기를 320x320, 352x352, ..., 608x608 로 resize 하면서 다양한 스케일로 학습

## 1) Batch Normalization ##

YOLO v1에서 사용되고 있는 convolution layer에 모두 batch normalization을 적용시켜 mAP 2% 성능향상을 기록했다.

***batch normalization이란?***

![image](https://user-images.githubusercontent.com/66320010/107905330-b9053780-6f91-11eb-9454-3b39703ba86b.png)

*배치 정규화는 활성화함수의 활성화값 또는 출력값을 정규화(정규분포로 만든다)하는 작업을 말한다. 신경망의 각 layer에서 데이터(배치)의 분포를 정규화하는 작업이다. 일종의 노이즈를 추가하는 방법으로 (bias와 유사) 이는 배치마다 정규화를 함으로써 전체 데이터에 대한 평균의 분산과 값이 달라질 수 있다. 학습을 할 때마다 활성화값/출력값을 정규화하기 때문에 초기화(가중치 초깃값) 문제에서 비교적 자유로워진다.*

## 2) High Resolution Classifier ##

YOLO v1에서 feature extraction목적으로 사용된 CNN모델은 VGG 16기반이다.

VGG 16은 224 x 224 이미지로 resize되어 학습하기 때문에 224 x 224 이미지에 대한 객체를 classification하는데 최적화 되어있다.

즉, 기존 YOLO v1 모델은 224 x 224 크기의 해상도로 학습된 VGG 모델을 가져온 다음, 448 x 448 크기의 이미지에 대해서 Object Detection을 수행하게끔 구성되어 있어 해상도가 맞지 않았다. 

따라서 448 x 448 이미지에 익숙하지 않은 VGG 16 기반의 CNN모델은 detection에서 성능저하를 일으킨다.

**-> YOLO v2에서는 Object Detection 학습 전에 ImageNet의 데이터셋에서 448 x 448 이미지들을 다시 학습시켜 fine tuning해주었고 그 결과 약 4% mAP가 증가했다.**

![image](https://user-images.githubusercontent.com/66320010/107907254-80b42800-6f96-11eb-866d-0d2e129b4b84.png)

YOLO v2는 YOLO v1과 달리 VGG Net 기반의 모델을 사용하지 않고 자체적으로 만든 CNN모델인 "darknet 19"사용한다.

darknet 19는 앞서 말한 기존 CNN모델의 성능 저하 문제를 해결하기 위해 처음에 224 x 224에 대한 ImageNet 데이터셋을 학습시키고 난 후 448 x 448 이미지에 대해서 재학습 시켜주어 fine tuning해주는 것이다(darknet 19를 이용한 결과 4% mAP가 증가한 것이다)

## 3) Anchor boxes ##

YOLO v2에서는 기존에 사용했던 Fully Connected Layer를 떼어내고 Fully Convolutional Network 형태로 prediction을 계산하고, anchor box의 개념을 도입한다.

여기서 중요한 점은 5차원 박스를 예측할 때 (중심점 x,y 좌표, 박스 너비 높이 w, h, 물체일 확률 c) 이렇게 다섯가지 정보를 합친 벡터를 사용했다는 것입니다. 

이는 사전에 박스는 어떠한 형태일 것이다라는 사전 정보 없이 그냥 박스를 prediction 하는 것이다. 때문에 예측하는 박스의 크기나 위치가 중구난방이 될 우려가 있다. 

따라서 YOLO v2에서는 anchor box의 개념을 도입한다.

Faster R-CNN의 RPN 구조를 보면 convoultion연산을 통해 RoI를 추출하는 작업을 한다.

![image](https://user-images.githubusercontent.com/66320010/107908088-94608e00-6f98-11eb-9cf6-7eab470d5944.png)

YOLO v1은 x,y,w,h값을 랜덤하게 설정해주고 직접 최적화된 값을 찾아가도록 학습하지만 Faster R-CNN은 사전에 anchor box 9개를 설정해주고 그에 따른 x,y,aspect ratio, object confidence score를 계산하면 되는 구조여서 훨씬 간단히 학습할 수 있었다.

(아무것도 모르는 상태에서 정답을 찾아가는거 보다 어느정도 틀이 갖추어진 상태에서 정답을 찾아가는것이 더 쉽다고 생각하면 된다)

**YOLO v2에서는 Faster R-CNN과 비슷한 region proposal방식을 사용한다. anchor box를 미리 선정하고 사용하기 때문에 FC Layer를 사용하지 않고 RPN과 비슷하게 convolution layer를 사용하게 된다.**

**3-1) Convolutional With Anchor Boxes**

위에서 darknet 19를 학습시킬 때에는 448 x 448 이미지를 학습시킨다고 했는데 detection을 진행할 때는 입력 이미지가 416 x 416으로 바뀌게 된다.

그 이유는 7 x 7 grid cell은 크기가 너무 작기 때문에 사실상 low resolution 상태에서 detection하는 것과 같고, 이전 YOLO 모델에서 적용한 bounding box의 갯수를 보면 7 x 7 x2 = 98개인데 이는 recall(대상 물체를 빠뜨리지 않고 얼마나 잘 잡아내는지) 관점에서는 터무니 없이 적은 갯수이기 때문이다.

따라서 anchor box갯수를 2개에서 5개로 늘려 설정하고 7 x 7 보다 더 큰 feature map size인 13 x 13으로 설정하면 13 x 13 x 5 = 845개의 bounding box를 사용할 수 있기 떄문에 더 많은 recall을 얻을 수 있다(하지만 mAP성능에서는 오히려 더 낮은 결과가 나오게 되었다)

**-> YOLO v2에서는 보통 물체가 이미지의 중앙에 있는 경우가 많다보니 홀수 x 홀수로 최종 output feature map을 설정해주는 것이 더 좋기 때문에 14 x 14가 아닌 13 x 13으로 맞춰주기 위해서 448 x 448을 416 x 416으로 변경해준 것이다.**

**3-2) Dimension Clusters**

Faster R-CNN에서 사용한 anchor box는 사전에 aspect ratio와 size를 다르게 하여 9개의 숫자로 미리 정해주었다. 

하지만 YOLO v2에서는 anchor box를 적용시킬 때 단순히 aspect ratio와 size를 통해 미리 정해준 anchor box를 사용하는 것이 문제가 있다고 판단하였다.

![image](https://user-images.githubusercontent.com/66320010/107910999-eefce880-6f9e-11eb-9933-ae3dd2bd1275.png)

그래서 YOLO v2는 training dataset에 있는 ground truth bounding box에 k-means clustering방법을 사용하여 최적의 anchor boxes를 찾는다.

<k-means clustering 예시>

![image](https://user-images.githubusercontent.com/66320010/107911241-78acb600-6f9f-11eb-8276-d798dfd59306.png)

step 1. k를 3이리ㅏ고 설정하면 임의의 데이터 3개를 지정하고 이 3개의 데이터를 기준으로 3개의 다른 영역을 구성하게 된다.

step 2. 3개의 다른 영역을 나눌 때, 지정된 3개의 data에서 가장 가까운 데이터들을 계산해 각각의 그룹을 형성한다.

step 3. 해당 그룹 내에서 데이터들간의 위치를 계산하여 그룹내에서 평균을 계산하고 그 평균을 기준으로 step2의 방식을 적용하여 다시 3개의 그룹을 형성한다.

step 4. step2와3을 반복하다보면 최적화된 clustering을 만들게 된다.

































