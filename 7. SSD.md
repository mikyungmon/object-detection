# SSD(Single Shot MultiBox Detector) #

![image](https://user-images.githubusercontent.com/66320010/108501327-7aa2ac00-72f4-11eb-97e7-18038c3d6410.png)

  - YOLO v1은 속도 측면에서 당시 Faster R-CNN이 7FPS이었던 것을 45FPS까지 끌어올리는 비약적인 발전을 이루었다.
  
  - 하지만 **정확도** 측면에서는 한계점이 있었고 **새 떼처럼 작은 물체들이 모여있는 경우에는 잘 잡아내지 못했다.**
  
    **=> SSD는 바로 이러한 한계점을 극복하고자 하는 시도에서 출발하였다.**
    
  - SSD의 핵심 아이디어
  
    - YOLO v1의 문제점은 입력 이미지를 7x7 의 그리드셀로 분할하여 각 그리드 셀을 중심으로 하는 각종 크기의 오브젝트에 대해서 경계박스 후보를 2개 예측하여 기존 R-CNN 계열은 후보를 1천개 이상 제안하는것에 비해 YOLO v1은 총 7x7x2 = 98개의 후보를 제안하므로 이로 인해 성능이 떨어진다는 것이다.
    
    - 또한 신경망을 모두 통과하면서 컨볼루션과 풀링을 거쳐 coarse한 정보만 남은 마지막 단 feature map만 사용하기 때문에 정확도가 하락하는 한계가 있었다.
    
    - 따라서 SSD는 이전 연구들에서 장점만 모아 이러한 YOLO v1의 한계점을 극복하고자 하였다.
  
   
    **"fully convolution network에서처럼 앞단 컨볼루션 피처맵을 끌어와 사용하여 detail을 잡아내고 Faster RCNN의 anchor 개념을 가져와 다양한 형태의 object들도 잡아낼 수 있도록 한다."**
    
# Architecture # 
  
![image](https://user-images.githubusercontent.com/66320010/108503394-a8d5bb00-72f7-11eb-9563-3092550e066b.png)

  - SSD는 YOLO v1과 달리 컨볼루션 과정을 거치는 중간 중간 feature map들에서 모두 Object Detection을 수행한다.
  
  - SSD는 300 x 300 크기의 이미지를 입력받아서 ImageNet으로 pretrained된 VGG의 Conv5_3층까지 통과하며 feature를 추출한다.

  - 그 다음, 추출된 feature map을 컨볼루션을 거쳐 다음 층으로 넘겨주는 동시에 object detection을 수행한다.

  **-> 이전 Fully Convolution Network에서 컨볼루션을 거치면서 디테일한 정보들이 사라지는 문제점을 앞단의 feature map들을 끌어오는 방식으로 해결한 것이다.**
  
  다시 설명하자면 
  
1) Modified VGG Net

   먼저 SSD는 VGG Net을 이용해 feature extraction하려고 했는데 이것을 그대로 이용하지 않고 SSD 모델에 맞게 수정해주었다. 아래 그림에서 어떻게 수정되었는지 설명하고 있다.

   ![image](https://user-images.githubusercontent.com/66320010/108504036-a45dd200-72f8-11eb-9982-7abda4f1b4fd.png)
   
2) Remove FC layer

   앞서 YOLO v2에서 FC layer를 제거시켜서 1) object detection 모델에서 입력 이미지를 고정시키지 않아도 된다. 2) parameters 갯수의 급격한 감소로 속도가 빨라진다. 는 효과를 얻었다.
   
   본래 YOLO v2는 SSD 다음에 나온 모델이기 때문에 SSD는 YOLO v2에서 FC layer를 제거하는 아이디어를 얻었을 가능성이 크다.
   
 3) Multi-map scale feature maps

   위에서 SSD 모델의 구조를 보면 detection을 하기위해 여러개의 feature map을 사용하는 것을 볼 수 있다.
   
   SSD 역시 그리드 셀 방식으로 운영이 되는데 YOLO v1에서 처럼 하나의 그리드 셀에서 고정된 갯수의 default 앵커 박스를 사용하게 된다.
   
   ![image](https://user-images.githubusercontent.com/66320010/108505350-96a94c00-72fa-11eb-890d-8f69fefa46bf.png)
   
   예를 들어 하나의 그리드 셀에서 생성하는 앵커 박스들의 크기가 동일하다면 작은 output feature map에서는 좀 더 큰 객체를 더 잘 탐지할 수 있고, 더 큰 output feature map에서는 작은 물체를 검출할 수 있는 가능성이 커진다. 
   
   그래서 **다양한 크기의 feature map**이 detection에서 좀 더 좋은 성능을 기대해 볼 수 있게 되는 것이다.
   
   
    















