# SSD(Single Shot MultiBox Detector) #

![image](https://user-images.githubusercontent.com/66320010/108501327-7aa2ac00-72f4-11eb-97e7-18038c3d6410.png)

  - YOLO v1은 속도 측면에서 당시 Faster R-CNN이 7FPS이었던 것을 45FPS까지 끌어올리는 비약적인 발전을 이루었다.
  
  - 하지만 **정확도** 측면에서는 한계점이 있었고 **새 떼처럼 작은 물체들이 모여있는 경우에는 잘 잡아내지 못했다.**
  
    **=> SSD는 바로 이러한 한계점을 극복하고자 하는 시도에서 출발하였다.**
    
  - SSD의 핵심 아이디어
  
    - YOLO v1의 문제점은 입력 이미지를 7x7 의 그리드셀로 분할하여 각 그리드 셀을 중심으로 하는 각종 크기의 오브젝트에 대해서 경계박스 후보를 2개 예측하여 기존 R-CNN 계열은 후보를 1천개 이상 제안하는것에 비해 YOLO v1은 총 7x7x2 = 98개의 후보를 제안하므로 이로 인해 성능이 떨어진다는 것이다.
    
    - 또한 신경망을 모두 통과하면서 컨볼루션과 풀링을 거쳐 coarse한 정보만 남은 마지막 단 feature map만 사용하기 때문에 정확도가 하락하는 한계가 있었다.
    
    - 따라서 SSD는 이전 연구들에서 장점만 모아 이러한 YOLO v1의 한계점을 극복하고자 하였다.
  
   
    **"fully convolution network에서처럼 앞단 컨볼루션 피처맵을 끌어와 사용하여 detail을 잡아내고 Faster RCNN의 anchor 개념을 가져와 다양한 형태의 object들도 잡아낼 수 있도록 한다."**
    
# Architecture # 
  
![image](https://user-images.githubusercontent.com/66320010/108503394-a8d5bb00-72f7-11eb-9563-3092550e066b.png)

  - SSD는 YOLO v1과 달리 컨볼루션 과정을 거치는 중간 중간 feature map들에서 모두 Object Detection을 수행한다.
  
  - SSD는 300 x 300 크기의 이미지를 입력받아서 ImageNet으로 pretrained된 VGG의 Conv5_3층까지 통과하며 feature를 추출한다.

  - 그 다음, 추출된 feature map을 컨볼루션을 거쳐 다음 층으로 넘겨주는 동시에 object detection을 수행한다.

  **-> 이전 Fully Convolution Network에서 컨볼루션을 거치면서 디테일한 정보들이 사라지는 문제점을 앞단의 feature map들을 끌어오는 방식으로 해결한 것이다.**
  
 이것을 좀 더 자세하게 표현한 그림은 아래와 같다.
 
 ![image](https://user-images.githubusercontent.com/66320010/108531969-a6d12380-731a-11eb-91ca-af68d369288b.png)
 
VGG를 통과하여 얻은 feature map을 대상으로 쭉쭉 컨볼루션 진행하여 최종적으로는 1 x 1크기의 feature map을 뽑는다.

그리고 각 단계별로 추출된 feature map은 Detector & Classifier를 통과하여 Object Detection을 수행한다.

![image](https://user-images.githubusercontent.com/66320010/108532467-3971c280-731b-11eb-9c55-9e12b8b434c8.png)

위의 그림은 Detector & Classifier의 구조이다.

예를 들어 컨볼루션 중간에 5  x5 x 256 크기의 피쳐맵을 대상으로 Object Detection을 수행한다고 가정해보자(여기서 5 x 5는 YOLO에서 그리드 크기에 해당한다고 생각하면 된다)

하나의 그리드마다 크기가 각기 다른 default box(비율과 크기가 각기 다른 기본박스를 설정해놓은 것)들을 먼저 계산하며 그림으로 나타내면 아래와 같다.

![image](https://user-images.githubusercontent.com/66320010/108533003-d6346000-731b-11eb-9b12-0c63bc452f9c.png)

**높은 해상도의 feature map에서는 작은 물체를 잘 잡아낼 수 있고 낮은 해상도에서는 큰 물체를 잘 잡아낼 것이라고 추측할 수 있다.**

SSD는 각각의 feature map을 가져와 비율과 크기가 각기 다른 dafault box를 투영하고 이렇게 찾아낸 박스들에 bounding box regression을 적용하고 confidence level을 계산한다 

**-> 이는 YOLO가 아무런 기본 값 없이 2개의 박스를 예측하도록 한 것과 대조적이다.**

Detector & Classifier의 구조를 보면 feature map에 3 x 3 컨볼루션을 적용해 bounding box regression값을 계산한다.

이는 각각 default box들의 x, y ,w, h의 조절값을 나타내므로 4차원 벡터에 해당하며 위 그림에서는 그리드 셀 하나에 3개의 default box를 적용하였기 때문에 결과 feature map의 크기는 5 x 5 x 12가 된다.

마지막으로 각각의 default box마다 모든 클래스에 대하여 classification을 진행하는데 총 20개의 클래스 + 1(배경 클래스) x default box 수 이므로 최종 feature map의 크기는 5 x 5 x 63이 된다. 

**(위의 내용을 정리 및 추가)**

1) Modified VGG Net

   먼저 SSD는 VGG Net을 이용해 feature extraction하려고 했는데 이것을 그대로 이용하지 않고 SSD 모델에 맞게 수정해주었다. 아래 그림에서 어떻게 수정되었는지 설명하고 있다.

   ![image](https://user-images.githubusercontent.com/66320010/108504036-a45dd200-72f8-11eb-9982-7abda4f1b4fd.png)
   
2) Remove FC layer

   앞서 YOLO v2에서 FC layer를 제거시켜서 1) object detection 모델에서 입력 이미지를 고정시키지 않아도 된다. 2) parameters 갯수의 급격한 감소로 속도가 빨라진다. 는 효과를 얻었다.
   
   본래 YOLO v2는 SSD 다음에 나온 모델이기 때문에 SSD는 YOLO v2에서 FC layer를 제거하는 아이디어를 얻었을 가능성이 크다.
   
 3) Multi-map scale feature maps

    위에서 SSD 모델의 구조를 보면 detection을 하기위해 여러개의 feature map을 사용하는 것을 볼 수 있다.
   
    SSD 역시 그리드 셀 방식으로 운영이 되는데 YOLO v1에서 처럼 하나의 그리드 셀에서 고정된 갯수의 default 앵커 박스를 사용하게 된다.
   
   ![image](https://user-images.githubusercontent.com/66320010/108505350-96a94c00-72fa-11eb-890d-8f69fefa46bf.png)
   
   예를 들어 하나의 그리드 셀에서 생성하는 앵커 박스들의 크기가 동일하다면 작은 output feature map에서는 좀 더 큰 객체를 더 잘 탐지할 수 있고, 더 큰 output feature map에서는 작은 물체를 검출할 수 있는 가능성이 커진다. 
   
   그래서 **다양한 크기의 feature map**이 detection에서 좀 더 좋은 성능을 기대해 볼 수 있게 되는 것이다.
   
 4) Detection

    앞서 SSD의 detection방식은 다양한 크기의 output feature map을 사용하는 것이었다.
   
    다양한 output feature map이 최종단계에서 어떻게 결합되는지 아래 그림을 통해 이해할 수 있다.
   
    ![image](https://user-images.githubusercontent.com/66320010/108536867-493fd580-7320-11eb-9ddd-86f12703e417.png)
   
    그림을 보면 각각의 컨볼루션에서 앵커 박스의 갯수를 다르게 설정했음을 알 수 있는데 그 이유는 명확하지 않으나 추측하기로는 아마 몇몇의 feature map에서 empirical하게 박스 갯수들에 대해서 실험을 해봤던 거 같다.
   
    그래서 몇몇의 feature map에서는 다른 default box shapes를 사용했다고 하는데 앵커박스 갯수가 6개인 곳은 기존 4개와 2개의 다른 앵커박스 모양이 추가된다.
    
    ![image](https://user-images.githubusercontent.com/66320010/108538049-b30caf00-7321-11eb-9534-bfc9778e6065.png)
    
 5) NMS

    위에서 보았듯이 8742 x (classes + 4) features를 뽑게되면 각각의 output feature map에서 뽑은 앵커박스들 때문에 최종 단계에서 한 객체에 대한 많은 bounding box가 생성된다.
    
    ![image](https://user-images.githubusercontent.com/66320010/108539040-ce2bee80-7322-11eb-9e61-00bb4fb7bef9.png)
    
    따라서 이전에 YOLO 에서 설명한 NMS 알고리즘에 따라 하나의 앵커 박스만 선택한다.

















