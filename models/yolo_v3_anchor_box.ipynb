{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBL(nn.Module):  # torch에 있는 module이라는걸 사용하기 위해 nn.module작성. Pytorch는 nn.module이라는\n",
    "                       # class를 제공하여 사용자가 이 위에서 자신이 필요로 하는 model architecture를 구현할 수 있도록 함\n",
    "    def __init__(self, input_ch, output_ch, kernel_size, strides, padding):\n",
    "        super(DBL, self).__init__()  # nn.module을 실행시키는데 필요\n",
    "        self.conv = nn.Conv2d(in_channels=input_ch,\n",
    "                              out_channels=output_ch,\n",
    "                              kernel_size=kernel_size,\n",
    "                              stride=strides,\n",
    "                              padding=padding,\n",
    "                              bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=output_ch)  # C from an expected input of size (N, C, H, W)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResUnit(nn.Module):\n",
    "    def __init__(self, input_ch, output_ch, double_out_ch):\n",
    "        super(ResUnit, self).__init__()  # nn.module을 실행시키는데 필요\n",
    "        self.darkDBL1 = DBL(input_ch=input_ch, output_ch=output_ch, kernel_size=1, strides=1, padding=0)\n",
    "        self.darkDBL2 = DBL(input_ch=output_ch, output_ch=double_out_ch, kernel_size=3, strides=1, padding=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.darkDBL1(inputs)\n",
    "        x = self.darkDBL2(x)\n",
    "        x = torch.add(inputs, x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Darknet53(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Darknet53, self).__init__()  # nn.module을 실행시키는데 필요\n",
    "        self.conv1 = DBL(input_ch=3, output_ch=32, kernel_size=3, strides=1, padding=1)\n",
    "        self.conv2 = DBL(input_ch=32, output_ch=64, kernel_size=3, strides=2, padding=1)\n",
    "\n",
    "        # res1\n",
    "        self.res1 = ResUnit(input_ch=64, output_ch=32, double_out_ch=64)\n",
    "\n",
    "        self.conv5 = DBL(input_ch=64, output_ch=128, kernel_size=3, strides=2, padding=1)\n",
    "\n",
    "        # res2\n",
    "        self.res2 = ResUnit(input_ch=128, output_ch=64, double_out_ch=128)\n",
    "\n",
    "        self.conv10 = DBL(input_ch=128, output_ch=256, kernel_size=3, strides=2, padding=1)\n",
    "\n",
    "        # res8\n",
    "        self.res3 = ResUnit(input_ch=256, output_ch=128, double_out_ch=256)\n",
    "\n",
    "        self.conv27 = DBL(input_ch=256, output_ch=512, kernel_size=3, strides=2, padding=1)\n",
    "\n",
    "        # res8\n",
    "        self.res4 = ResUnit(input_ch=512, output_ch=256, double_out_ch=512)\n",
    "\n",
    "        self.conv44 = DBL(input_ch=512, output_ch=1024, kernel_size=3, strides=2, padding=1)\n",
    "\n",
    "        # res4\n",
    "        self.res5 = ResUnit(input_ch=1024, output_ch=512, double_out_ch=1024)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        for i in range(2):\n",
    "            x = self.res2(x)\n",
    "\n",
    "        x = self.conv10(x)\n",
    "\n",
    "        for i in range(8):\n",
    "            x = self.res3(x)\n",
    "\n",
    "        y3 = x\n",
    "        x = self.conv27(x)\n",
    "\n",
    "        for i in range(8):\n",
    "            x = self.res4(x)\n",
    "\n",
    "        y2 = x\n",
    "        x = self.conv44(x)\n",
    "\n",
    "        for i in range(4):\n",
    "            x = self.res5(x)\n",
    "        y1 = x\n",
    "\n",
    "        return y1, y2, y3  # y1 : 13*13*1024 , y2: 26*26*512, y3: 52*52*256\n",
    "\n",
    "\n",
    "class DBL5(nn.Module):\n",
    "    def __init__(self, input_ch, output_ch):\n",
    "        super(DBL5, self).__init__()\n",
    "        self.d_1 = DBL(input_ch=input_ch, output_ch=input_ch, kernel_size=1, strides=1, padding=0)\n",
    "        self.d_2 = DBL(input_ch=input_ch, output_ch=input_ch, kernel_size=3, strides=1, padding=1)\n",
    "        self.d_3 = DBL(input_ch=input_ch, output_ch=input_ch, kernel_size=1, strides=1, padding=0)\n",
    "        self.d_4 = DBL(input_ch=input_ch, output_ch=input_ch, kernel_size=3, strides=1, padding=1)\n",
    "        self.d_5 = DBL(input_ch=input_ch, output_ch=output_ch, kernel_size=1, strides=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.d_1(inputs)\n",
    "        x = self.d_2(x)\n",
    "        x = self.d_3(x)\n",
    "        x = self.d_4(x)\n",
    "        x = self.d_5(x)\n",
    "        return x\n",
    "    \n",
    "class Small(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Small, self).__init__()\n",
    "        self.d5 = DBL5(input_ch=1024, output_ch=512)  # 13*13*512\n",
    "        self.dbl1 = DBL(input_ch=512, output_ch=1024, kernel_size=3, strides=1, padding=1)  # 13*13*1024\n",
    "        self.conv = nn.Conv2d(in_channels=1024, out_channels=255, kernel_size=1, stride=1, padding=0)  # 13*13*255\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        small = self.d5(inputs)\n",
    "        s1 = small\n",
    "        small = self.dbl1(small)\n",
    "        small = self.conv(small)\n",
    "        return s1, small  # s1: 13*13*512, small : 13*13*255\n",
    "\n",
    "\n",
    "class Medium(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Medium, self).__init__()\n",
    "        self.dbl = DBL(input_ch=512, output_ch=256, kernel_size=1, strides=1, padding=0)  # 13*13*256\n",
    "        self.up_sample = nn.Upsample(scale_factor=2, mode='nearest')  # 크기를 2배로 늘림 # 26*26*256\n",
    "        self.dbl5 = DBL5(input_ch=768, output_ch=256)  # 26*26*(256+512) in , 26*26*256 out\n",
    "        self.after_dbl = DBL(input_ch=256, output_ch=512, kernel_size=3, strides=1, padding=1)  # 26*26*512\n",
    "        self.conv = nn.Conv2d(in_channels=512, out_channels=255, kernel_size=1, stride=1, padding=0)  # 26*26*255\n",
    "\n",
    "    def forward(self, s1, y2):\n",
    "        medium = self.dbl(s1)\n",
    "        medium = self.up_sample(medium)  # 26*26*256\n",
    "        # print(\"medium_shape:\", medium.shape)\n",
    "        medium = torch.cat((medium, y2), dim=1)  # dim=1 열로 합치기\n",
    "        medium = self.dbl5(medium)\n",
    "        m1 = medium\n",
    "        medium = self.after_dbl(medium)\n",
    "        medium = self.conv(medium)\n",
    "\n",
    "        return m1, medium\n",
    "\n",
    "\n",
    "class Large(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Large, self).__init__()\n",
    "        self.dbl = DBL(input_ch=256, output_ch=128, kernel_size=1, strides=1, padding=0)  # in 26*26*256 out 26*26*128\n",
    "        self.up_sample = nn.Upsample(scale_factor=2, mode='nearest')  # 52*52*128\n",
    "        self.dbl5 = DBL5(input_ch=384, output_ch=128)  # in 52*52*(128+256) out 52*52*128\n",
    "        self.after_dbl = DBL(input_ch=128, output_ch=256, kernel_size=3, strides=1, padding=1)  # 52*52*256\n",
    "        self.conv = nn.Conv2d(in_channels=256, out_channels=255, kernel_size=1, stride=1, padding=0)  # 52*52*255\n",
    "\n",
    "    def forward(self, m1, y3):\n",
    "        large = self.dbl(m1)\n",
    "        large = self.up_sample(large)\n",
    "        large = torch.cat((large, y3), dim=1)\n",
    "        large = self.dbl5(large)\n",
    "        large = self.after_dbl(large)\n",
    "        large = self.conv(large)\n",
    "\n",
    "        return large\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# anchor box detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLODetection(nn.Module):\n",
    "    def __init__(self, anchors, image_size, num_classes):\n",
    "        super(YOLODetection, self).__init__()\n",
    "        self.anchors = anchors\n",
    "        self.num_anchors = len(anchors)\n",
    "        self.num_classes = num_classes\n",
    "        self.image_size = image_size\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.ignore_thres = 0.5\n",
    "        self.obj_scale = 1\n",
    "        self.no_obj_scale = 100\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        batch_size = x.size(0)\n",
    "        grid_size = x.size(2)\n",
    "\n",
    "        # 출력값 형태 변환하기\n",
    "        prediction = (\n",
    "            x.view(batch_size, self.num_anchors, self.num_classes + 5, grid_size, grid_size).permute(0, 1, 3, 4, 2)\n",
    "                .contiguous())  # contiguous()는 tensor에서 바로 옆에 있는 요소가 실제로 메모리상에서 서로 인접한 것\n",
    "\n",
    "        # outputs\n",
    "        bx = torch.sigmoid(prediction[..., 0])  # Center x   # 앞의 값은 모두 포함하고 맨 뒤에 인덱스는 0번 인덱스만 포함한다는 뜻\n",
    "        by = torch.sigmoid(prediction[..., 1])  # Center y\n",
    "        bw = prediction[..., 2]  # Width\n",
    "        bh = prediction[..., 3]  # Height\n",
    "        pred_conf = torch.sigmoid(prediction[..., 4])  # Object confidence (objectness)\n",
    "        pred_cls = torch.sigmoid(prediction[..., 5:])  # Class prediction\n",
    "\n",
    "        # 각 그리드에 맞춰 offsets 계산하기\n",
    "        stride = self.image_size / grid_size\n",
    "        cx = torch.arange(grid_size, dtype=torch.float).repeat(grid_size, 1).view(\n",
    "            [1, 1, grid_size, grid_size])\n",
    "        # arange 는 주어진 범위 내 정수를 순서대로 생성 , repeat는 dim=0으로 grid size만큼 dim=1로 1만큼 반복 의미\n",
    "        cy = torch.arange(grid_size, dtype=torch.float).repeat(grid_size, 1).t().view(\n",
    "            [1, 1, grid_size, grid_size])\n",
    "        scaled_anchors = torch.as_tensor([(a_w / stride, a_h / stride) for a_w, a_h in self.anchors],\n",
    "                                         dtype=torch.float)\n",
    "        # scaled_anchors 에는 w와 h값 밖에 없는데 왜 굳이 [:,0:1]이라고 써주는지..? 질문\n",
    "        anchor_w = scaled_anchors[:, 0:1].view((1, self.num_anchors, 1, 1))\n",
    "        anchor_h = scaled_anchors[:, 1:2].view((1, self.num_anchors, 1, 1))\n",
    "\n",
    "        # anchors 에 offset 과 scale 추가\n",
    "        pred_boxes = torch.zeros_like(prediction[..., :4])\n",
    "        pred_boxes[..., 0] = bx + cx\n",
    "        pred_boxes[..., 1] = by + cy\n",
    "        pred_boxes[..., 2] = torch.exp(bw) * anchor_w\n",
    "        pred_boxes[..., 3] = torch.exp(bh) * anchor_h\n",
    "\n",
    "        # x,y,w,h와 conf,cls 합치기\n",
    "        # stride 곱해서 이미지에서 실제 좌표로 만들어주기\n",
    "        pred = (pred_boxes.view(batch_size, -1, 4) * stride,  # batch_size 가 의미하는건 무엇인지..? 굳이 여기 있는 이유는?\n",
    "                pred_conf.view(batch_size, -1, 1),\n",
    "                pred_cls.view(batch_size, -1, self.num_classes))\n",
    "        output = torch.cat(pred, -1)\n",
    "\n",
    "        if targets is None:\n",
    "            return output, 0\n",
    "\n",
    "        iou_scores, class_mask, obj_mask, no_obj_mask, tx, ty, tw, th, tcls, tconf = utils.build_targets(pred_boxes=pred_boxes, pred_cls=pred_cls,\n",
    "                                                                                                         target=targets, anchors=scaled_anchors\n",
    "                                                                                                            , ignore_thres=self.ignore_thres)\n",
    "\n",
    "        # Loss 구하기(존재하지 않는 object를 무시하도록 mask. conf.loss는 제외)\n",
    "        loss_x = self.mse_loss(bx[obj_mask], tx[obj_mask])\n",
    "        loss_y = self.mse_loss(by[obj_mask], ty[obj_mask])\n",
    "        loss_w = self.mse_loss(bw[obj_mask], tw[obj_mask])\n",
    "        loss_h = self.mse_loss(bh[obj_mask], th[obj_mask])\n",
    "        loss_bbox = loss_x + loss_y + loss_w + loss_h\n",
    "        \n",
    "        # bounding box안에 물체가 있는지 없는지에 대한 loss\n",
    "        # 왜 bce loss썼는지?\n",
    "        loss_conf_obj = self.bce_loss(pred_conf[obj_mask], tconf[obj_mask])\n",
    "        loss_conf_no_obj = self.bce_loss(pred_conf[no_obj_mask], tconf[no_obj_mask])\n",
    "        # scale 은 패널티 의미. 물체가 없을 때 있다고 하면 더 크게 패널티를 줌\n",
    "        loss_conf = self.obj_scale * loss_conf_obj + self.no_obj_scale * loss_conf_no_obj \n",
    "        \n",
    "        # class 예측에 대한 loss\n",
    "        loss_cls = self.bce_loss(pred_cls[obj_mask], tcls[obj_mask])\n",
    "\n",
    "        loss_layer = loss_bbox + loss_conf + loss_cls\n",
    "\n",
    "        return output, loss_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolo v3 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOv3, self).__init__()\n",
    "        anchors = {'a1': [(10, 13), (16, 30), (33, 23)],\n",
    "                   'a2': [(30, 61), (62, 45), (59, 119)],\n",
    "                   'a3': [(116, 90), (156, 198), (373, 326)]}\n",
    "       \n",
    "        self.image_size = 416\n",
    "        self.num_classes = 80\n",
    "\n",
    "        self.darknet53 = Darknet53()\n",
    "        \n",
    "        self.small =  Small()\n",
    "        self.yolo_layer_1 = YOLODetection(anchors['a3'], self.image_size, self.num_classes)\n",
    "        \n",
    "        self.medium =  Medium()\n",
    "        self.yolo_layer_2 = YOLODetection(anchors['a2'], self.image_size, self.num_classes)\n",
    "\n",
    "        self.large = Large()\n",
    "        self.yolo_layer_3 = YOLODetection(anchors['a1'], self.image_size, self.num_classes)\n",
    "\n",
    "        self.yolo_layer = [self.yolo_layer_1, self.yolo_layer_2, self.yolo_layer_3]\n",
    "\n",
    "    def forward(self, x,targets=None):\n",
    "        loss = 0\n",
    "        \n",
    "        y1, y2, y3 = Darknet53().forward(x)\n",
    "        \n",
    "        # 1번 feature뽑기\n",
    "        s1, feature1 = self.small(y1)\n",
    "        output_1,loss_1 = self.yolo_layer_1(feature1)  \n",
    "        print(\"feature1:\", feature1.shape)\n",
    "        # output1 shape: [1, 507, 85]\n",
    "        # 507 -> 13*13*3 -> feature1 크기가 13*13인데 한 그리드당 앵커박스가 3개.따라서 507은 feature map1에서의 총 앵커박스 갯수 \n",
    "        print(\"output1:\", output_1.shape) \n",
    "        loss += loss_1\n",
    "        \n",
    "        # 2번 feature뽑기\n",
    "        m1, feature2 = self.medium(s1, y2)\n",
    "        output_2, loss_2 = self.yolo_layer_2(feature2)\n",
    "        print(\"feature2:\", feature2.shape)\n",
    "        # output2 shape: [1, 2028, 85]\n",
    "        # 2028 -> feature2(26*26*255)에서 총 앵커박스 갯수\n",
    "        print(\"output2:\", output_2.shape)  \n",
    "        loss += loss_2\n",
    "\n",
    "        # 3번 feature뽑기\n",
    "        feature3 = self.large(m1, y3)\n",
    "        output_3, loss_3 = self.yolo_layer_3(feature3)\n",
    "        print(\"feature3:\", feature3.shape)\n",
    "        # output3 shape: [1, 8112, 85]\n",
    "        # 8112 -> feature3(52*52*255)에서 총 앵커박스 갯수\n",
    "        print(\"output3:\", output_3.shape)\n",
    "        loss += loss_3\n",
    "\n",
    "        \n",
    "        yolo_outputs = [output_1, output_2, output_3]\n",
    "        yolo_outputs = torch.cat(yolo_outputs, 1).detach().cpu()\n",
    "        print(\"yolo_outputs:\", yolo_outputs.shape)\n",
    "       \n",
    "        return yolo_outputs if targets is None else (loss, yolo_outputs)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1: torch.Size([1, 255, 13, 13])\n",
      "output1: torch.Size([1, 507, 85])\n",
      "feature2: torch.Size([1, 255, 26, 26])\n",
      "output2: torch.Size([1, 2028, 85])\n",
      "feature3: torch.Size([1, 255, 52, 52])\n",
      "output3: torch.Size([1, 8112, 85])\n",
      "yolo_outputs: torch.Size([1, 10647, 85])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.8867e+01, 8.5678e+00, 1.5555e+02,  ..., 4.0639e-01,\n",
       "          4.7577e-01, 5.4579e-01],\n",
       "         [4.5812e+01, 1.6206e+01, 1.9945e+02,  ..., 4.3902e-01,\n",
       "          5.8473e-01, 5.6389e-01],\n",
       "         [8.1117e+01, 7.8442e+00, 1.1157e+02,  ..., 3.2755e-01,\n",
       "          5.4057e-01, 4.6846e-01],\n",
       "         ...,\n",
       "         [3.9637e+02, 4.1152e+02, 2.8234e+01,  ..., 6.0236e-01,\n",
       "          6.2611e-01, 3.9036e-01],\n",
       "         [4.0454e+02, 4.1248e+02, 3.3793e+01,  ..., 5.5719e-01,\n",
       "          5.1352e-01, 4.9397e-01],\n",
       "         [4.1260e+02, 4.1140e+02, 2.9150e+01,  ..., 5.5994e-01,\n",
       "          5.0180e-01, 5.6049e-01]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, 3, 416, 416)  # 랜덤 이미지 생성\n",
    "YOLOv3().forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object",
   "language": "python",
   "name": "object_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
